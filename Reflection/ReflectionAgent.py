# å‡è®¾ llm_client.py å’Œ memory.py å·²å®šä¹‰
from LLM import HelloAgentsLLM
# from memory import Memory
from text.index import INITIAL_PROMPT_TEMPLATE, REFINE_PROMPT_TEMPLATE, REFLECT_PROMPT_TEMPLATE
from Memory import Memory

class ReflectionAgent:
    def __init__(self, llm_client, max_iterations=3):
        self.llm_client = llm_client
        self.memory = Memory()
        self.max_iterations = max_iterations

    def run(self, task: str):
        print(f"\n--- å¼€å§‹å¤„ç†ä»»åŠ¡ ---\nä»»åŠ¡: {task}")

        # --- 1. åˆå§‹æ‰§è¡Œ ---
        print("\n--- æ­£åœ¨è¿›è¡Œåˆå§‹å°è¯• ---")
        initial_prompt = INITIAL_PROMPT_TEMPLATE.format(task=task)
        initial_code = self._get_llm_response(initial_prompt)
        self.memory.add_record("execution", initial_code)

        # --- 2. è¿­ä»£å¾ªç¯:åæ€ä¸ä¼˜åŒ– ---
        for i in range(self.max_iterations):
            print(f"\n--- ç¬¬ {i + 1}/{self.max_iterations} è½®è¿­ä»£ ---")

            # a. åæ€
            print("\n-> æ­£åœ¨è¿›è¡Œåæ€...")
            last_code = self.memory.get_last_execution()
            reflect_prompt = REFLECT_PROMPT_TEMPLATE.format(task=task, code=last_code)
            feedback = self._get_llm_response(reflect_prompt)
            self.memory.add_record("reflection", feedback)

            # b. æ£€æŸ¥æ˜¯å¦éœ€è¦åœæ­¢
            if "æ— éœ€æ”¹è¿›" in feedback:
                print("\nâœ… åæ€è®¤ä¸ºä»£ç å·²æ— éœ€æ”¹è¿›ï¼Œä»»åŠ¡å®Œæˆã€‚")
                break

            # c. ä¼˜åŒ–
            print("\n-> æ­£åœ¨è¿›è¡Œä¼˜åŒ–...")
            refine_prompt = REFINE_PROMPT_TEMPLATE.format(
                task=task,
                last_code_attempt=last_code,
                feedback=feedback
            )
            refined_code = self._get_llm_response(refine_prompt)
            self.memory.add_record("execution", refined_code)

        final_code = self.memory.get_last_execution()
        print(f"\n--- ä»»åŠ¡å®Œæˆ ---\næœ€ç»ˆç”Ÿæˆçš„ä»£ç :\n```python\n{final_code}\n```")
        return final_code

    def _get_llm_response(self, prompt: str) -> str:
        """ä¸€ä¸ªè¾…åŠ©æ–¹æ³•ï¼Œç”¨äºè°ƒç”¨LLMå¹¶è·å–å®Œæ•´çš„æµå¼å“åº”ã€‚"""
        messages = [{"role": "user", "content": prompt}]
        response_text = self.llm_client.think(messages=messages) or ""
        return response_text


if __name__ == "__main__":
    from LLM import HelloAgentsLLM
    from Memory import Memory

    # 1. åˆå§‹åŒ–å¤§æ¨¡å‹å®¢æˆ·ç«¯
    llm = HelloAgentsLLM()

    # 2. åˆ›å»ºåæ€ä»£ç†ï¼ˆæœ€å¤šè¿­ä»£2è½®ï¼ŒèŠ‚çœæ—¶é—´ï¼‰
    agent = ReflectionAgent(llm_client=llm, max_iterations=2)

    # 3. å®šä¹‰æµ‹è¯•ä»»åŠ¡
    task = "å†™ä¸€ä¸ªPythonå‡½æ•°ï¼Œæ¥æ”¶ä¸¤ä¸ªæ•°å­—å¹¶è¿”å›å®ƒä»¬çš„å’Œ"

    # 4. è¿è¡Œä»£ç†
    print(f"\nğŸš€ å¼€å§‹æµ‹è¯•ä»»åŠ¡: {task}\n")
    final_code = agent.run(task)

    # 5. è¾“å‡ºæœ€ç»ˆä»£ç 
    print("\n" + "=" * 50)
    print("âœ… æœ€ç»ˆç”Ÿæˆçš„ä»£ç ï¼š")
    print("=" * 50)
    print(final_code)